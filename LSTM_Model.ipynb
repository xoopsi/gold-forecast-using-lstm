{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "T5eRJCnf1lbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxMxBWKAqm9r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import optuna\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_DNnkEKH10A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡\n",
        "file_path = '/content/drive/My Drive/My_data/XAUUSD_M15_2020_2024.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.tail(2)"
      ],
      "metadata": {
        "id": "HniMpbjE2hMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´\n",
        "label_mapping = {'b': 0, 's': 1, 'n': 2}\n",
        "df['Lable'] = df['Lable'].map(label_mapping).fillna(-1).astype(int)\n",
        "\n",
        "feature_columns = ['Open', 'High', 'Low', 'Close', 'tenkan', 'kijun', 'senkou_a', 'senkou_b', 'spanb_high_index',\n",
        "                   'spanb_low_index', 'kijun_104', 'komo_sen', 'komo']\n",
        "\n",
        "columns_to_normalize = ['Open', 'High', 'Low', 'Close', 'tenkan', 'kijun', 'senkou_a', 'senkou_b', 'kijun_104']\n",
        "df_normalized = df.copy()\n",
        "scaler = MinMaxScaler()\n",
        "df_normalized[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])"
      ],
      "metadata": {
        "id": "94PeBELd2hKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø°Ø®ÛŒØ±Ù‡ Scaler Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ\n",
        "joblib.dump(scaler, '/content/drive/My Drive/My_data/minmax_scaler_1.pkl')"
      ],
      "metadata": {
        "id": "DysHKgFK2hHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ø³Ø§Ø®Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ\n",
        "timesteps = 52\n",
        "X, y = [], []\n",
        "for i in range(timesteps - 1, len(df_normalized)):\n",
        "    label = df_normalized['Lable'].iloc[i]\n",
        "    if pd.notna(label) and label in [0, 1, 2]:\n",
        "        sample = df_normalized[feature_columns].iloc[i - timesteps + 1:i + 1].values\n",
        "        X.append(sample)\n",
        "        y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "29K3S5QV2hEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
      ],
      "metadata": {
        "id": "jJtZJxjf2g6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- One-hot Encoding\n",
        "y_train_onehot = to_categorical(y_train, num_classes=3)\n",
        "y_test_onehot = to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "4bv9QnrN2g4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø¨Ù‡ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§\n",
        "class_weights = {0: 1.0 / 0.27, 1: 1.0 / 0.38, 2: 1.0 / 0.35}\n",
        "total = sum(class_weights.values())\n",
        "class_weights = {k: v / total for k, v in class_weights.items()}\n",
        "sample_weights = np.array([class_weights[int(i)] for i in y_train])"
      ],
      "metadata": {
        "id": "5tGw_ouK2g1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„\n",
        "def create_model(trial):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(timesteps, len(feature_columns))))\n",
        "\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    for i in range(num_layers):\n",
        "        units = trial.suggest_categorical(f\"units_{i}\", [32, 64, 128, 256])\n",
        "        return_seq = i < num_layers - 1\n",
        "        model.add(LSTM(units, return_sequences=return_seq))\n",
        "        dropout_rate = trial.suggest_float(f\"dropout_{i}\", 0.2, 0.5)\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\", \"nadam\"])\n",
        "    optimizer = {\n",
        "        'adam': Adam(learning_rate),\n",
        "        'rmsprop': RMSprop(learning_rate),\n",
        "        'sgd': SGD(learning_rate),\n",
        "        'nadam': Nadam(learning_rate)\n",
        "    }[optimizer_name]\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cRCPjHh52gyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ØªØ§Ø¨Ø¹ Ù‡Ø¯Ù Optuna\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(X_train, y_train_onehot,\n",
        "                        epochs=42,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_test, y_test_onehot),\n",
        "                        sample_weight=sample_weights,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=0)\n",
        "\n",
        "    val_loss, val_accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
        "    return val_accuracy"
      ],
      "metadata": {
        "id": "3-K_HS_V2gvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=75)"
      ],
      "metadata": {
        "id": "zy1QT6wn3GCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±ÛŒÙ† Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\n",
        "print(\"\\nâœ… Ø¨Ù‡ØªØ±ÛŒÙ† Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "8i_w1gRS3F8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Best Parameters\n",
        "# num_layers: 3\n",
        "# units_0: 256\n",
        "# dropout_0: 0.24078446184580357\n",
        "# units_1: 128\n",
        "# dropout_1: 0.3664629266022855\n",
        "# units_2: 64\n",
        "# dropout_2: 0.29437184419705087\n",
        "# learning_rate: 0.0016267447887427097\n",
        "# optimizer: adam\n",
        "# batch_size: 16"
      ],
      "metadata": {
        "id": "o5N9cg9SSRYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ø¢Ù…ÙˆØ²Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„\n",
        "best_trial = study.best_trial\n",
        "final_model = create_model(best_trial)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "final_model.fit(X_train, y_train_onehot,\n",
        "                epochs=50,\n",
        "                batch_size=best_trial.params['batch_size'],\n",
        "                validation_data=(X_test, y_test_onehot),\n",
        "                sample_weight=sample_weights,\n",
        "                callbacks=[early_stopping],\n",
        "                verbose=1)"
      ],
      "metadata": {
        "id": "WkKCPVO43F3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test_onehot, axis=1)"
      ],
      "metadata": {
        "id": "arQQRQuV3F0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "print(\"\\nğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=['Buy', 'Sell', 'No Action']))\n"
      ],
      "metadata": {
        "id": "pequhGdv4esF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Buy', 'Sell', 'No Action'], yticklabels=['Buy', 'Sell', 'No Action'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1cAtluGt4jSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "final_model.save('/content/drive/My Drive/My_data/best_lstm_evolution_model_1.h5')"
      ],
      "metadata": {
        "id": "m4aJKUl24m1F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}